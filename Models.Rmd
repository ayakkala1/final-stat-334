---
title: "Models"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(car)
library(xtable)
library(broom)
library(olsrr)
```

## Setup

```{r prework ,message=FALSE, warning=FALSE}
alpha <- 0.05

find_sig <- function(model, alpha, bonferonni = F){
  if(bonferonni){
  model %>%
    filter(p.value < alpha/(nrow(model1_sum))) %>%
    select(term, estimate, p.value)
  }
  else{
  model %>%
    filter(p.value < alpha) %>%
    select(term, estimate, p.value)
  }
}

colleges <- read_csv(paste0("https://raw.githubusercontent.com/",
                           "ayakkala1/final-stat-334/",
                           "master/data/USNews.csv"))
colleges <- colleges %>%
              drop_na()

head(colleges)
```

## Model Information

Response: __GradRate__ (in percent of students who graduate within 6 years)

###  Variables for USNews Data

1. College name
2. State (postal code)
3. Funding (categorical variable: Public or Private)
4. Number of applications received (in number of students)
5. Number of applicants accepted (in number of students)
6. Number of new students enrolled (in number of students)
7. Pct. new students from top 10% of H.S. class (in percent)
8. Number of fulltime undergraduates (in number of students)
9. Out-of-state tuition (in dollars)
10. Room and board costs (in dollars)
11. Pct. of faculty with Ph.D.'s (in percent)
12. Student/facultyratio (instudents per faculty member)
13. Pct.alumni who donate (in percent)
14. Instructionalexpenditureperstudent (in dollars)
15. Graduation rate (in percent of students who graduate within 6 years)
16. StdScore = the average of standardized SAT and ACT scores for students at the school (in standard deviations above or below average)

Missing values are denoted with *

## Default Model

```{r Default Model Summary}
explanatory <- names(colleges)[names(colleges) != "Gradrate"]

model1 <- lm(Gradrate ~ Funding + Apps + Accepted + 
                        Enrolled + Top10 + FTUG + 
                        Tuition + RmBrd + PhD + 
                        SFRatio + Alumni + Spending + StdScore, 
             data = colleges)

model1_sum <- tidy(summary(model1))

model1_sum
```

```{r warning=TRUE}
n <- nrow(colleges)
p <- length(explanatory) + 1

outlier.test.cutoff <- qt(.05/(2*n),n - p - 1,lower.tail=FALSE)

residuals.1 <- rstudent(model1)
obs.1 <- names(residuals.1)

as_tibble(cbind(obs.1,as.numeric(residuals.1))) %>%
  filter(abs(residuals.1) > outlier.test.cutoff)
```

Observation 391 is an outlier

```{r}
numerics <- unlist(lapply(colleges, is.numeric))

college.q.mat <- as.matrix(colleges[,numerics])

colleges[391,"Name"]
print(scale(college.q.mat)[391,"Gradrate"])
```

As we can see Cazenovia College is the only extreme outlier with a Graduation Rate that is 3.154105 standard deviations away from the sample mean Graduation Rate.

```{r}
colleges[391,"Gradrate"]
```

It looks like this is a mistake in the data entry because it is impossible for a college to have 118% graduation rate.

```{r}
X <- model.matrix(Gradrate ~ Funding + Apps + Accepted + 
                        Enrolled + Top10 + FTUG + 
                        Tuition + RmBrd + PhD + 
                        SFRatio + Alumni + Spending + StdScore, 
             data = colleges)

H <- X %*% solve(t(X) %*% X) %*% t(X)

h.values <- as.numeric(diag(H))

obs.1 <- names(h.values)

as_tibble(cbind(obs.1,h.values)) %>%
  filter(h.values > ((3 * p)/n)) %>%
  arrange(desc(h.values))
```


```{r Influential Observations, message=FALSE, warning=FALSE}
cook.cutoff <- qf(0.5,p,n - p)

cooks.values <- tidy(cooks.distance(model1))

cooks.values %>% 
  filter(x > cook.cutoff)
```

None of our observations our influential.

```{r Significant Variables}
sig.1 <- find_sig(model1_sum, alpha, bonferonni = F)
sig.1
```


```{r VIF, message=FALSE, warning=FALSE}
ols_vif_tol(model1) %>%
  filter(VIF >= 4)
```
Apps, Accepted, Enrolled, and Full Time Undergraduate all have serious multicollinearity issues, while tuition has a moderate multicollinearity.

```{r residualPlots}
residualPlots(model1, type = "rstudent")

qqPlot(rstudent(model1),distribution="norm",pch = 20,id = FALSE)

shapiro.test(model1$residuals)

hist(model1$residuals)

```

- Application
  - CV : Fan In
  - Linearity: Okay
- Accepted
  - CV: Fan in
  - Linearity: Okay
- Enrolled
  - CV: Fan in
  - Linearity: Okay
- Top10
  - CV: Fan In
  - Linearity: Okay
- FTUG
  - CV: Fan in
  - Linearity: Okay
- Tuition
  - CV: Good
  - Linearity: Good
- RmBrd
  - CV: Good
  - Linearity: Good
- PhD
  - CV: Good
  - Linearity: Good
- SFRatio
  - CV: Okay
  - Linearity: Good
- Alumni
  - CV: Good
  - Linearity: Good
- Spending
  - CV: Fan In
  - Linearity: Okay
- StdScore
  - CV: Good
  - Linearity: Good
- Fitted Values
  - CV: Okay
  - Linearity: Okay
  
```{r Correlation with Response}
numerics <- unlist(lapply(colleges, is.numeric))

correlations <- c()
numeric_names <- names(colleges[,numerics])

for (i in colleges[,numerics]){
  correlations <- c(correlations, cor(colleges$Gradrate, i))
}

cor_with_grad <- as_tibble(cbind(numeric_names, correlations))

cor_with_grad %>%
  mutate(correlations = as.numeric(correlations)) %>%
  filter(numeric_names != "Gradrate") %>%
  mutate(numeric_names = fct_reorder(numeric_names, correlations)) %>%
  ggplot(aes(x = numeric_names, y = correlations, fill = numeric_names)) +
          geom_col() + coord_flip() + guides(fill = FALSE) +
          xlab(element_blank()) + ylab("Correlation") +
          ggtitle("Correlation with Graduation Rate") +
          scale_y_continuous(breaks = seq(-1, 1, by = 0.1))
```

```{r corrplot, message=FALSE, warning=FALSE, fig.height=8, fig.width = 8}
library(corrplot)

college_corr <- cor(colleges[, numerics], method = "pearson")

corrplot(college_corr, 
         type = "upper", 
         order = "hclust", 
         tl.col = "black", 
         tl.srt = 45)
```

Now to drop Casenovia College
We need to change the State variable to a Region variable

```{r}
colleges <- colleges[-c(391),]

NE.abrv <- c("CT","ME","MA","NH","RI","VT","NJ","NY","PA")
NE.ref <- c(NE.abrv)


MW.abrv <- c("IN","IL","MI","OH","WI","IA","KS","MN","MO","NE",
             "ND","SD")
MW.ref <- c(MW.abrv)


S.abrv <- c("DE","DC","FL","GA","MD","NC","SC","VA","WV","AL",
            "KY","MS","TN","AR","LA","OK","TX")
S.ref <- c(S.abrv)

W.abrv <- c("AZ","CO","ID","NM","MT","UT","NV","WY","AK","CA",
            "HI","OR","WA")
W.ref <- c(W.abrv)

region.list <- list(
  Northeast=NE.ref,
  Midwest=MW.ref,
  South=S.ref,
  West=W.ref)

colleges$Region <- sapply(colleges$State, 
                 function(x) names(region.list)[grep(x,region.list)])

#drop State
colleges <- colleges[ , !(names(colleges) %in% "State")]
```

```{r}
model1 <- lm(Gradrate ~ Funding + Apps + Accepted + 
                        Enrolled + Top10 + FTUG + 
                        Tuition + RmBrd + PhD + 
                        SFRatio + Alumni + Spending + StdScore, 
             data = colleges)
```

# Model 1.5/2

Our first plan is to create a new variable that is Accepted/Apps to get a standardized acceptance rate for each college, and also fix the high VIF.

Drop FTUG
Drop Enrolled

```{r}
colleges <- colleges %>%
              mutate(Acceptance_Rate = Accepted/Apps)
```

```{r}
model1.5 <- lm(Gradrate ~ Funding + Apps + Accepted + 
                        Enrolled + Top10 + FTUG + 
                        Tuition + RmBrd + PhD + 
                        SFRatio + Alumni + Spending + StdScore + Region,
             data = colleges)

anova(model1.5,model1)
```

We reject the null hypothesis so we can conclude that that Region is associated with Graduation Rate.

```{r}
summary(model1.5)
ols_vif_tol(model1.5) %>%
  filter(VIF >= 4)
```

```{r residualPlots}
model1.5 <- lm(Gradrate  ~ Funding + Apps + Accepted + 
                        Enrolled + Top10 + FTUG + 
                        Tuition + RmBrd + PhD + 
                        SFRatio + Alumni + Spending + StdScore + Region,
             data = colleges)

residualPlots(model1.5, type = "rstudent")

qqPlot(rstudent(model1.5),distribution="norm",pch = 20,id = FALSE)

shapiro.test(model1.5$residuals)

hist(model1.5$residuals)

```

```{r}
model2 <- lm(Gradrate ~ Funding + Apps  + 
                         Top10 + 
                        Tuition  + 
                        Alumni + Spending + StdScore + Region, 
             data = colleges)

anova(model2,model1.5)
```

We fail to reject the null hypothesis that the slope coefficients for Enrolled, FTUG, Accepted, Rmbd, SFRatio ,PhD are equal to 0. Meaning that we can not reject for each of those predictor variables there is no association with Graduation Rate.

So we will drop the variables.

```{r}
model3 <- lm(Gradrate ~ Funding + Apps  + 
                         Top10 + Acceptance_Rate +
                        Tuition + 
                        Alumni + Spending + StdScore + Region, 
             data = colleges)

model3_sum <- summary(model3)

model3_sum
```

```{r warning=FALSE}
ols_vif_tol(model3) %>%
  filter(VIF >= 4)
```

It appears that our Accpetance_rate variable is still insignificant using the t-test. So we willnot keep it in our model.

```{r}
model4 <- lm(Gradrate ~ Funding + Apps  + 
                         Top10  +
                        Tuition + 
                        Alumni + Spending + StdScore + Region, 
             data = colleges)

model4_sum <- summary(model4)

model4_sum
```

```{r}
residualPlots(model4, type = "rstudent")

qqPlot(rstudent(model4),distribution="norm",pch = 20,id = FALSE)

shapiro.test(model4$residuals)

hist(model4$residuals)
```

```{r}
colleges$cApps <- scale(colleges$Apps,scale=FALSE)
colleges$cTop10 <- scale(colleges$Top10,scale=FALSE)
colleges$cTuition <- scale(colleges$Tuition,scale=FALSE)
colleges$cAlumni <- scale(colleges$Alumni,scale=FALSE)
colleges$cSpending <- scale(colleges$Spending,scale=FALSE)
colleges$cStdScore <- scale(colleges$StdScore,scale=FALSE)

# Make Quality a factor with Moderate as the baseline group
colleges$Funding <- factor(colleges$Funding)
colleges$Region <- factor(colleges$Region)
# Run the full model, model0

full <- lm(Gradrate ~ Funding + cApps  + 
                         cTop10  +
                        cTuition + 
                        cAlumni + cSpending + cStdScore + Region +
                    Region * cApps, 
             data = colleges)

# Run a best subsets regression on model0 using the "olsrr" package
subsets <- ols_step_all_possible(full)

# View the data table showing all of the models
View(subsets)

# Plot the fit statistics for each model
plot(subsets)

# Find the model(s) that maximum Adj.R2 and minimize Cp and BIC
best.sub <- data.frame(
  Adj.R2 = which.max(subsets$adjr),
  CP = which.min(subsets$cp),
  BIC = which.min(subsets$sbc)
)

# Display the index of the best model by each criterion
best.sub

# Display the best model based on Mallow's Cp
subsets[best.sub$CP,]
```

```{r}
residualPlots(model3, type = "rstudent")

qqPlot(rstudent(model3),distribution = "norm",pch = 20,id = FALSE)

shapiro.test(model3$residuals)

hist(model3$residuals)
```

## Model 4/5

```{r}
model4 <- lm(Gradrate ~ Funding + Apps  + 
                         Acceptance_Rate +
                        Tuition + RmBrd  + 
                         Alumni + Spending + StdScore, 
             data = colleges)

model4_sum <- tidy(summary(model4))

model4_sum
```

```{r}
anova(model3,model4)
```

We fail to reject the null hypothesis that there is no association for Gradrate and amount of PhD Students adjusted for the other predictor variabels, no association between Gradrate and Student Faculty Ratio adjusted for the other predictor variables, and no association between Gradrate and percent of students coming from top 10 highschools adjusted for other predictor variables.

So we do not have enough evidence to not drop amount of PhD Students, Student Faculty Ratio, and percent of students coming from top 10 highschools from our model.

```{r}
find_sig(model4_sum, 0.05, bonferonni = F)
```

```{r message=FALSE, warning=FALSE}
ols_vif_tol(model4) %>%
  filter(VIF >= 4)
```

```{r}
colleges <- colleges %>%
              mutate(Gradrate_sqrt = Gradrate ^ 0.5)

model5 <- lm(Gradrate_sqrt ~ Funding + Apps  + 
                         Acceptance_Rate +
                        Tuition + RmBrd  + 
                         Alumni + Spending + StdScore, 
             data = colleges)

model5_sum <- tidy(summary(model5))

model5_sum
```

```{r}
residualPlots(model1, type = "rstudent")
residualPlots(model5, type = "rstudent")

qqPlot(rstudent(model1),distribution = "norm",pch = 20,id = FALSE)
qqPlot(rstudent(model5),distribution = "norm",pch = 20,id = FALSE)

shapiro.test(model5$residuals)

hist(model5$residuals)
```

```{r}
avPlots(model5,pch=20,id=FALSE)
```

```{r}
colleges %>%
  arrange(desc(Apps))
```

