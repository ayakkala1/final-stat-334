---
title: "Models"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(car)
library(xtable)
library(broom)
library(olsrr)
```

## Setup

```{r prework ,message=FALSE, warning=FALSE}
alpha <- 0.05

find_sig <- function(model, alpha, bonferonni = F){
  if(bonferonni){
  model %>%
    filter(p.value < alpha/(nrow(model1_sum))) %>%
    select(term, estimate, p.value)
  }
  else{
  model %>%
    filter(p.value < alpha) %>%
    select(term, estimate, p.value)
  }
}

colleges <- read_csv(paste0("https://raw.githubusercontent.com/",
                           "ayakkala1/final-stat-334/",
                           "master/data/USNews.csv"))
colleges <- colleges %>%
              drop_na()

head(colleges)
```

## Model Information

Response: __GradRate__ (in percent of students who graduate within 6 years)

###  Variables for USNews Data

1. College name
2. State (postal code)
3. Funding (categorical variable: Public or Private)
4. Number of applications received (in number of students)
5. Number of applicants accepted (in number of students)
6. Number of new students enrolled (in number of students)
7. Pct. new students from top 10% of H.S. class (in percent)
8. Number of fulltime undergraduates (in number of students)
9. Out-of-state tuition (in dollars)
10. Room and board costs (in dollars)
11. Pct. of faculty with Ph.D.'s (in percent)
12. Student/facultyratio (instudents per faculty member)
13. Pct.alumni who donate (in percent)
14. Instructionalexpenditureperstudent (in dollars)
15. Graduation rate (in percent of students who graduate within 6 years)
16. StdScore = the average of standardized SAT and ACT scores for students at the school (in standard deviations above or below average)

Missing values are denoted with *

## Default Model

```{r}

NE.abrv <- c("CT","ME","MA","NH","RI","VT","NJ","NY","PA")
NE.ref <- c(NE.abrv)


MW.abrv <- c("IN","IL","MI","OH","WI","IA","KS","MN","MO","NE",
             "ND","SD")
MW.ref <- c(MW.abrv)


S.abrv <- c("DE","DC","FL","GA","MD","NC","SC","VA","WV","AL",
            "KY","MS","TN","AR","LA","OK","TX")
S.ref <- c(S.abrv)

W.abrv <- c("AZ","CO","ID","NM","MT","UT","NV","WY","AK","CA",
            "HI","OR","WA")
W.ref <- c(W.abrv)

region.list <- list(
  Northeast=NE.ref,
  Midwest=MW.ref,
  South=S.ref,
  West=W.ref)

colleges$Region <- sapply(colleges$State, 
                 function(x) names(region.list)[grep(x,region.list)])

#drop State
colleges <- colleges[ , !(names(colleges) %in% "State")]
```

```{r Default Model Summary}
explanatory <- names(colleges)[names(colleges) != "Gradrate"]

model1 <- lm(Gradrate ~ Funding + Apps + Accepted + 
                        Enrolled + Top10 + FTUG + 
                        Tuition + RmBrd + PhD + 
                        SFRatio + Alumni + Spending + StdScore + Region,
             data = colleges)

model1_sum <- tidy(summary(model1))

model1_sum
```

```{r warning=TRUE}
n <- nrow(colleges)
p <- length(explanatory) + 1

outlier.test.cutoff <- qt(.05/(2*n),n - p - 1,lower.tail=FALSE)

residuals.1 <- rstudent(model1)
obs.1 <- names(residuals.1)

as_tibble(cbind(obs.1,as.numeric(residuals.1))) %>%
  filter(abs(residuals.1) > outlier.test.cutoff)
```

Observation 391 is an outlier

```{r}
numerics <- unlist(lapply(colleges, is.numeric))

college.q.mat <- as.matrix(colleges[,numerics])

colleges[391,"Name"]
print(scale(college.q.mat)[391,"Gradrate"])
```

As we can see Cazenovia College is the only extreme outlier with a Graduation Rate that is 3.154105 standard deviations away from the sample mean Graduation Rate.

```{r}
colleges[391,"Gradrate"]
```

It looks like this is a mistake in the data entry because it is impossible for a college to have 118% graduation rate.

```{r}
X <- model.matrix(Gradrate ~ Funding + Apps + Accepted + 
                        Enrolled + Top10 + FTUG + 
                        Tuition + RmBrd + PhD + 
                        SFRatio + Alumni + Spending + StdScore, 
             data = colleges)

H <- X %*% solve(t(X) %*% X) %*% t(X)

h.values <- as.numeric(diag(H))

obs.1 <- names(h.values)

as_tibble(cbind(obs.1,h.values)) %>%
  filter(h.values > ((3 * p)/n)) %>%
  arrange(desc(h.values))
```

```{r Influential Observations, message=FALSE, warning=FALSE}
cook.cutoff <- qf(0.5,p,n - p)

cooks.values <- tidy(cooks.distance(model1))

cooks.values %>% 
  filter(x > cook.cutoff)
```

Now to drop Casenovia College
We need to createa Region variable from the State variable.

We use the codes from the U.S census.

```{r}
colleges <- colleges[-c(391),]
```

# Model 1.5/2

Now to fix multicollinearity

```{r}
ols_vif_tol(model1)
```


```{r}
colleges <- colleges %>%
              mutate(Acceptance_Rate = Accepted/Apps)

colleges$Yield <- colleges$Enrolled/colleges$Accepted
colleges$RatioFA <- colleges$FTUG/colleges$Apps
```

```{r}
model2 <- lm(Gradrate ~ Funding + Acceptance_Rate + Apps + 
                        Yield + Top10 + RatioFA + 
                        Tuition + RmBrd + PhD + 
                        SFRatio + Alumni + Spending + StdScore + Region, 
             data = colleges)

ols_vif_tol(model2) %>%
  filter(VIF >= 3)
```

```{r}
colleges$cApps <- scale(colleges$Apps,scale=FALSE)
colleges$cTop10 <- scale(colleges$Top10,scale=FALSE)
colleges$cTuition <- scale(colleges$Tuition,scale=FALSE)
colleges$cAlumni <- scale(colleges$Alumni,scale=FALSE)
colleges$cSpending <- scale(colleges$Spending,scale=FALSE)
colleges$cStdScore <- scale(colleges$StdScore,scale=FALSE)
colleges$cAcceptance_Rate <- scale(colleges$Acceptance_Rate,scale=FALSE)
colleges$cYield <- scale(colleges$Yield,scale=FALSE)
colleges$cSFRatio <- scale(colleges$SFRatio,scale=FALSE)
colleges$cRmBrd <- scale(colleges$RmBrd,scale=FALSE)
colleges$cPhD <- scale(colleges$PhD,scale=FALSE)
colleges$cRatioFA <- scale(colleges$RatioFA,scale=FALSE)

# Make Quality a factor with Moderate as the baseline group
colleges$Funding <- factor(colleges$Funding)
colleges$Region <- factor(colleges$Region)
# Run the full model, model0

full <- lm(Gradrate ~ Funding + cAcceptance_Rate + cApps + 
                        cYield + cTop10 + cRatioFA + 
                        cTuition + cRmBrd + cPhD + 
                        cSFRatio + cAlumni + cSpending + cStdScore + Region, 
             data = colleges)

# Run a best subsets regression on model0 using the "olsrr" package
subsets <- ols_step_all_possible(full)

# View the data table showing all of the models
View(subsets)

# Plot the fit statistics for each model
plot(subsets)

# Find the model(s) that maximum Adj.R2 and minimize Cp and BIC
best.sub <- data.frame(
  Adj.R2 = which.max(subsets$adjr),
  CP = which.min(subsets$cp),
  BIC = which.min(subsets$sbc)
)

# Display the index of the best model by each criterion
best.sub

# Display the best model based on Mallow's Cp
subsets[best.sub$CP,]
```

Funding cAcceptance_Rate cApps cTop10 cTuition cRmBrd cAlumni cSpending cStdScore Region


```{r}
model3 <- lm(Gradrate ~ Funding + cAcceptance_Rate + cApps + cTop10 + 
                 cTuition + cRmBrd + cAlumni + cSpending + cStdScore + Region, data = colleges)
```


```{r}
model3.1 <- lm(Gradrate ~ Funding + cAcceptance_Rate + cApps + cTop10 + 
                 cTuition + cRmBrd + cAlumni + cSpending + cStdScore + Region +
               Region * cAcceptance_Rate + Region * cApps + Region * cTop10 +
               Region * cTuition + Region * cRmBrd + Region * cAlumni + Region * cSpending +
               Region * cStdScore, data = colleges)

summary(model3.1)

anova(model3,model3.1)
```



So we can no reason not to drop all of the interactions with Region

```{r}
model3.2 <- lm(Gradrate ~ Funding + cAcceptance_Rate + cApps + cTop10 + 
                 cTuition + cRmBrd + cAlumni + cSpending + cStdScore + Region +
               Funding * cAcceptance_Rate + Funding * cApps + Funding * cTop10 +
               Funding * cTuition + Funding * cRmBrd + Funding * cAlumni + Funding * cSpending +
               Funding * cStdScore, data = colleges)

anova(model3,model3.2)
```


So we have no reason not to drop all the interactions with Funding



```{r}
model3.3 <- lm(Gradrate ~ Funding + cAcceptance_Rate + cApps + cTop10 + 
                 cTuition + cRmBrd + cAlumni + cSpending + cStdScore + Region +
               Funding * Region, data = colleges)

summary(model3.3)

anova(model3,model3.3)
```

So we have no reason not to drop all the interactions

```{r}
quant_coeff <- c("cAcceptance_Rate","cApps","cTop10","cTuition","cRmBrd","cAlumni","cSpending","cStdScore")
combos <- combn(quant_coeff,2)

model3.4 <- lm(Gradrate ~ Funding + cAcceptance_Rate + cApps + cTop10 + 
                 cTuition + cRmBrd + cAlumni + cSpending + cStdScore + Region +
               cAcceptance_Rate * cApps +  cAcceptance_Rate * cTop10 + cAcceptance_Rate * cTuition + cAcceptance_Rate * cRmBrd +
                 cAcceptance_Rate * cAlumni + cAcceptance_Rate * cSpending + cAcceptance_Rate * cStdScore + 
                 cApps * cTop10 + cApps * cTuition + cApps * cRmBrd + cApps * cAlumni + cApps * cSpending + cApps * cStdScore + 
                 cTop10 * cTuition + cTop10 * cRmBrd + cTop10 * cAlumni + cTop10 * cSpending +cTop10 * cStdScore + 
                 cTuition * cRmBrd + cTuition * cAlumni + cTuition * cSpending + cTuition * cStdScore + 
                 cRmBrd * cAlumni + cRmBrd * cSpending +  cRmBrd * cStdScore +  cAlumni * cSpending +  cAlumni * cStdScore +  cSpending * cStdScore
                 , data = colleges)

summary(model3.4)

anova(model3,model3.4)
```

There are some interactions that are associated with Graduation Rate

Lets see if there is evidence we should not drop all the non significnat interactions.
```{r}
model3.5 <- lm(Gradrate ~ Funding + cAcceptance_Rate + cApps + cTop10 + 
                 cTuition + cRmBrd + cAlumni + cSpending + cStdScore + Region +
               cTop10:cSpending + cApps:cRmBrd  + cApps:cStdScore 
                 , data = colleges)

anova(model3.4,model3.5)
```

```{r}
summary(model3.5)
```

```{r}
model3.6 <-  lm(Gradrate ~ Funding + cApps + cTop10 + 
                 cTuition + cRmBrd + cAlumni + cSpending + cStdScore + Region +
               cTop10:cSpending + cApps:cRmBrd  + cApps:cStdScore 
                 , data = colleges)

anova(model3.5,model3.6)
```

```{r}
summary(model3.6)
```


```{r LastModelPlots}
model3.6 <-  lm(Gradrate ~ Funding + cApps + cTop10 + 
                 cTuition + cRmBrd + cAlumni + cSpending + cStdScore + Region +
               cTop10:cSpending + cApps:cRmBrd  + cApps:cStdScore 
                 , data = colleges)

residualPlots(model3.6, type = "rstudent")

qqPlot(rstudent(model3.6),distribution="norm",pch = 20,id = FALSE)

shapiro.test(model3.6$residuals)

hist(model3.6$residuals)
```

```{r}
n <- nrow(colleges)
p <- length(model3.6)

outlier.test.cutoff <- qt(.05/(2*n),n - p - 1,lower.tail=FALSE)

residuals.1 <- rstudent(model3.6)
obs.1 <- names(residuals.1)

as_tibble(cbind(obs.1,as.numeric(residuals.1))) %>%
  filter(abs(residuals.1) > outlier.test.cutoff)
```

```{r}
X <- model.matrix(Gradrate ~ Funding + cApps + cTop10 + 
                 cTuition + cRmBrd + cAlumni + cSpending + cStdScore + Region +
               cTop10:cSpending + cApps:cRmBrd  + cApps:cStdScore 
                 , data = colleges)

H <- X %*% solve(t(X) %*% X) %*% t(X)

h.values <- as.numeric(diag(H))

obs.1 <- names(h.values)

as_tibble(cbind(obs.1,h.values)) %>%
  filter(h.values > ((3 * p)/n)) %>%
  arrange(desc(h.values))
```


```{r}
cook.cutoff <- qf(0.5,p,n - p)

cooks.values <- tidy(cooks.distance(model3.6))

cooks.values %>% 
  filter(x > cook.cutoff)
```
